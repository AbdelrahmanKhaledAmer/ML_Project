{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Model_28145.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "0ix2eyZWzCWa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        },
        "outputId": "a9111797-ad5e-49fd-9597-dc1e51ec1bd9"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv2D, MaxPooling2D, Dropout, Flatten\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.preprocessing import image\n",
        "from PIL import Image\n",
        "import glob\n",
        "from google.colab import drive\n",
        "from keras.models import load_model\n",
        "\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "# Specify the input shape to the first convolutional layer\n",
        "input_shape = (120, 160, 3)\n",
        "nClasses = 2\n",
        "def createModel():\n",
        "    model = Sequential()\n",
        "    # a convolution layer of 32 features of size 3x3 with relu activation and zero padding\n",
        "    model.add(Conv2D(32, (3, 3), padding='same', activation='relu', input_shape=input_shape))\n",
        "    # a convolution layer of 32 features of size 3x3 with relu activation\n",
        "    model.add(Conv2D(32, (3, 3), activation='relu'))\n",
        "    # a batch normalization layer\n",
        "    model.add(BatchNormalization())\n",
        "    # maxpooling layer of filter size 2x2\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    \n",
        "    # a convolution layer of 64 features of size 3x3 with relu activation and zero padding\n",
        "    model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
        "    # a convolution layer of 64 features of size 3x3 with relu activation\n",
        "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "    # a batch normalization layer\n",
        "    model.add(BatchNormalization())\n",
        "    # maxpooling layer of filter size 2x2\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    \n",
        "    # a convolution layer of 64 features of size 3x3 with relu activation and zero padding\n",
        "    model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
        "    # a convolution layer of 64 features of size 3x3 with relu activation\n",
        "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "    # a batch normalization layer\n",
        "    model.add(BatchNormalization())\n",
        "    # maxpooling layer of filter size 2x2\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    # a dropout layer of 50%\n",
        "    model.add(Dropout(0.5))\n",
        "    \n",
        "    # flatten the output of the previous layer\n",
        "    model.add(Flatten())\n",
        "    # add a dense layer that outputs 512 units and apply relu activation\n",
        "    model.add(Dense(512, activation='relu'))\n",
        "    # a dropout layer of 50%\n",
        "    model.add(Dropout(0.5))\n",
        "    # add a dense layer with a softmax activation to classify the images\n",
        "    model.add(Dense(nClasses, activation='softmax'))\n",
        "     \n",
        "    return model\n",
        "  \n",
        "model2 = createModel()\n",
        "model2.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "GML-4oGHfVSo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Loading the data into a generator\n",
        "- SPE is argmument used later for  steps per epoch for training and validation"
      ]
    },
    {
      "metadata": {
        "id": "k91A_PFEzwpP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "6e2ee93a-aba8-4328-cb5f-166cc618b12c"
      },
      "cell_type": "code",
      "source": [
        "# !ls \"/content/gdrive/My Drive/Colab Notebooks/content/binaryD/Data\"\n",
        "\n",
        "# odata = []\n",
        "# print(len(sorted(glob.glob('/content/gdrive/My Drive/Colab Notebooks/content/binaryD/Data/train/positive/*.png'))))\n",
        "# for filename in sorted(glob.glob('/content/gdrive/My Drive/Colab Notebooks/content/binaryD/Data/train/*.png')): \n",
        "#     im=Image.open(filename)\n",
        "#     odata.append(im)\n",
        "    \n",
        "# print(\"odatalen: \",len(odata))\n",
        "\n",
        "trainGen = image.ImageDataGenerator(featurewise_center=False, samplewise_center=True, featurewise_std_normalization=False, samplewise_std_normalization=True, fill_mode='nearest',validation_split = 0.2)\n",
        "testGen = image.ImageDataGenerator(featurewise_center=False, samplewise_center=True, featurewise_std_normalization=False, samplewise_std_normalization=True, channel_shift_range=0.0, fill_mode='nearest')\n",
        "mainPath = '/content/gdrive/My Drive/Colab Notebooks/content/binaryD/'\n",
        "++6\n",
        "train_generator = trainGen.flow_from_directory(mainPath+'Data/train', target_size=(120, 160), batch_size=32, class_mode='binary',subset = \"training\")\n",
        "validation_generator = trainGen.flow_from_directory(mainPath+'Data/train', target_size=(120, 160), batch_size=32, class_mode='binary',subset = \"validation\")\n",
        "test_generator = testGen.flow_from_directory(mainPath+'Data/test', target_size=(120, 160), batch_size=32, class_mode='binary')\n",
        "SPE = 3872/32\n",
        "print(train_generator[0][0].shape)\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 3098 images belonging to 2 classes.\n",
            "Found 774 images belonging to 2 classes.\n",
            "Found 860 images belonging to 2 classes.\n",
            "(32, 120, 160, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "6ymdk84vdg1d",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Fitting the model\n",
        "- use keras callbacks for saving the best model and early stopping\n",
        "- steps per epoch = num train / batchsize\n",
        "- steps per epoch = num validation / batchsize\n",
        "\n",
        "both arguments control th data to be transfered using the generator. since each batch has a size of batch size, using the numbers above we make sure that the generator produce the whole training and validation data, In other words it produces steps per epoch  batches of training data. The test and validation data generator behaves in the same manner.\n"
      ]
    },
    {
      "metadata": {
        "id": "OFd-5rIZefUf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Complete training the provided model"
      ]
    },
    {
      "metadata": {
        "id": "maXpXEfadtMt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1042
        },
        "outputId": "1b0d0010-336c-4d3f-a5c0-c87ebabf9c91"
      },
      "cell_type": "code",
      "source": [
        "train_generator.reset()\n",
        "model2 = load_model(mainPath+\"Weights/weights.hdf5\")\n",
        "saveBest2 = keras.callbacks.ModelCheckpoint(mainPath+\"model2SampleNorm.hdf5\", monitor='val_acc', verbose=0, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
        "earlyStopping2 = keras.callbacks.EarlyStopping(monitor='val_acc', min_delta=0, patience=15, verbose=0, mode='auto', baseline=None, restore_best_weights=False)\n",
        "\n",
        "model2.fit_generator(train_generator, epochs=30, verbose = 1,validation_data = validation_generator,steps_per_epoch = SPE*0.8,validation_steps = SPE*0.2,callbacks = [saveBest2,earlyStopping2])\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "97/96 [==============================] - 573s 6s/step - loss: 0.4278 - acc: 0.8714 - val_loss: 0.6333 - val_acc: 0.8540\n",
            "Epoch 2/30\n",
            "97/96 [==============================] - 570s 6s/step - loss: 0.3726 - acc: 0.8889 - val_loss: 0.7857 - val_acc: 0.8501\n",
            "Epoch 3/30\n",
            "97/96 [==============================] - 566s 6s/step - loss: 0.3592 - acc: 0.9022 - val_loss: 0.8933 - val_acc: 0.8437\n",
            "Epoch 4/30\n",
            "97/96 [==============================] - 568s 6s/step - loss: 0.3326 - acc: 0.9123 - val_loss: 0.7618 - val_acc: 0.8760\n",
            "Epoch 5/30\n",
            "97/96 [==============================] - 570s 6s/step - loss: 0.3304 - acc: 0.9178 - val_loss: 1.0282 - val_acc: 0.8708\n",
            "Epoch 6/30\n",
            "97/96 [==============================] - 567s 6s/step - loss: 0.2617 - acc: 0.9283 - val_loss: 0.5203 - val_acc: 0.9096\n",
            "Epoch 7/30\n",
            "97/96 [==============================] - 569s 6s/step - loss: 0.2379 - acc: 0.9388 - val_loss: 0.9508 - val_acc: 0.8514\n",
            "Epoch 8/30\n",
            "97/96 [==============================] - 567s 6s/step - loss: 0.2346 - acc: 0.9415 - val_loss: 1.7712 - val_acc: 0.8307\n",
            "Epoch 9/30\n",
            "97/96 [==============================] - 568s 6s/step - loss: 0.2269 - acc: 0.9493 - val_loss: 1.0888 - val_acc: 0.8721\n",
            "Epoch 10/30\n",
            "97/96 [==============================] - 570s 6s/step - loss: 0.2196 - acc: 0.9491 - val_loss: 1.2126 - val_acc: 0.8514\n",
            "Epoch 11/30\n",
            "97/96 [==============================] - 571s 6s/step - loss: 0.1749 - acc: 0.9626 - val_loss: 1.7010 - val_acc: 0.8256\n",
            "Epoch 12/30\n",
            "97/96 [==============================] - 572s 6s/step - loss: 0.1672 - acc: 0.9613 - val_loss: 0.7409 - val_acc: 0.8966\n",
            "Epoch 13/30\n",
            "97/96 [==============================] - 569s 6s/step - loss: 0.1737 - acc: 0.9593 - val_loss: 1.0744 - val_acc: 0.8734\n",
            "Epoch 14/30\n",
            "97/96 [==============================] - 572s 6s/step - loss: 0.1497 - acc: 0.9644 - val_loss: 1.3295 - val_acc: 0.8450\n",
            "Epoch 15/30\n",
            "97/96 [==============================] - 568s 6s/step - loss: 0.1610 - acc: 0.9640 - val_loss: 0.8184 - val_acc: 0.8966\n",
            "Epoch 16/30\n",
            "97/96 [==============================] - 568s 6s/step - loss: 0.1692 - acc: 0.9645 - val_loss: 0.7839 - val_acc: 0.9018\n",
            "Epoch 17/30\n",
            "97/96 [==============================] - 566s 6s/step - loss: 0.1390 - acc: 0.9697 - val_loss: 0.6400 - val_acc: 0.9121\n",
            "Epoch 18/30\n",
            "97/96 [==============================] - 566s 6s/step - loss: 0.1138 - acc: 0.9709 - val_loss: 0.7918 - val_acc: 0.9096\n",
            "Epoch 19/30\n",
            "97/96 [==============================] - 569s 6s/step - loss: 0.1119 - acc: 0.9762 - val_loss: 0.7373 - val_acc: 0.9070\n",
            "Epoch 20/30\n",
            "97/96 [==============================] - 570s 6s/step - loss: 0.1168 - acc: 0.9758 - val_loss: 0.6447 - val_acc: 0.9160\n",
            "Epoch 21/30\n",
            "97/96 [==============================] - 568s 6s/step - loss: 0.0796 - acc: 0.9813 - val_loss: 0.8655 - val_acc: 0.9134\n",
            "Epoch 22/30\n",
            "97/96 [==============================] - 567s 6s/step - loss: 0.1103 - acc: 0.9790 - val_loss: 1.1390 - val_acc: 0.9005\n",
            "Epoch 23/30\n",
            "97/96 [==============================] - 568s 6s/step - loss: 0.0979 - acc: 0.9816 - val_loss: 0.9198 - val_acc: 0.9057\n",
            "Epoch 24/30\n",
            "97/96 [==============================] - 569s 6s/step - loss: 0.1166 - acc: 0.9822 - val_loss: 3.2347 - val_acc: 0.7674\n",
            "Epoch 25/30\n",
            "97/96 [==============================] - 569s 6s/step - loss: 0.1121 - acc: 0.9829 - val_loss: 0.6382 - val_acc: 0.9186\n",
            "Epoch 26/30\n",
            "97/96 [==============================] - 569s 6s/step - loss: 0.0836 - acc: 0.9836 - val_loss: 0.7631 - val_acc: 0.9134\n",
            "Epoch 27/30\n",
            "97/96 [==============================] - 565s 6s/step - loss: 0.0812 - acc: 0.9829 - val_loss: 0.7891 - val_acc: 0.9109\n",
            "Epoch 28/30\n",
            "97/96 [==============================] - 565s 6s/step - loss: 0.0680 - acc: 0.9868 - val_loss: 0.7756 - val_acc: 0.9160\n",
            "Epoch 29/30\n",
            "97/96 [==============================] - 566s 6s/step - loss: 0.0560 - acc: 0.9851 - val_loss: 0.7704 - val_acc: 0.9083\n",
            "Epoch 30/30\n",
            "97/96 [==============================] - 564s 6s/step - loss: 0.0721 - acc: 0.9839 - val_loss: 1.2062 - val_acc: 0.8773\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fa7ecd6e9e8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "metadata": {
        "id": "0NFSxQT_z5A6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Model evaluation\n",
        "- validation and testing results\n",
        "- it should be noted that the numbers below change when performing multiple runs "
      ]
    },
    {
      "metadata": {
        "id": "PaGUtr_FrOEw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "f6c99df1-493b-46dd-c13d-36824584365d"
      },
      "cell_type": "code",
      "source": [
        "# test_generator.reset()\n",
        "TPE=860/32\n",
        "model2 = load_model(mainPath+\"model2SampleNorm.hdf5\")\n",
        "print(model2.metrics_names,\" ===validation===>\",model2.evaluate_generator(generator = validation_generator,steps =SPE*0.2 ))\n",
        "\n",
        "print(model2.metrics_names,\" ===test===>\",model2.evaluate_generator(generator = test_generator,steps =TPE ))\n",
        "# model2.save(mainPath+\"model2.h5\")\n",
        "# model2 = load_model(mainPath+\"model2.h5\")"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['loss', 'acc']  ===validation===> [0.6089755097889636, 0.9211886304909561]\n",
            "['loss', 'acc']  ===test===> [0.30915737449841524, 0.9593023253041645]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5TNgXS2TumW4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}