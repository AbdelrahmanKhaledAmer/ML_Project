{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2\n",
    "## Stock Prices Time Series Prediction\n",
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data into memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('sp500.csv')\n",
    "data = data.drop(['Unnamed: 0'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix = data.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find Highest correlation\n",
    "Get the single column with the highest correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_correlations = np.array(correlation_matrix[['SP500']])[1:]\n",
    "correlation_index = np.argmax(sp_correlations) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract The Desired Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "desired_stock = data.iloc[:, correlation_index]\n",
    "\n",
    "input_set_1d  = np.array(desired_stock)\n",
    "output_set_1d = np.array(desired_stock.shift(-5).dropna())\n",
    "# instead of shifting in pandas we construct time sequence in a more traditional way\n",
    "def construct_time_series(best_stock_id,data):\n",
    "    x = []\n",
    "    y = []\n",
    "    windowSize = 4\n",
    "    for i in range(data.shape[0] - 2 * windowSize):\n",
    "        x += [data[best_stock_id][i:i + windowSize+1]]\n",
    "        y += [data[best_stock_id][i + windowSize + 1:i + 2 *windowSize + 1]]\n",
    "\n",
    "    return np.array(x), np.array(y)\n",
    "\n",
    "input_set, output_set = construct_time_series(data.columns[correlation_index],data)\n",
    "\n",
    "train_ratio = 0.8\n",
    "test_ratio  = 0.2\n",
    "valid_ratio = 0.1 # Will be used in the MLPClassifier to take 10% of the training data as validation\n",
    "\n",
    "training_input, testing_input, training_target, testing_target = train_test_split(input_set,output_set,\n",
    "                                                                                  test_size=test_ratio,\n",
    "                                                                                  random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Linear regressor\n",
    "The best MLP is implemented using adam optimizer with the parameters stated below.\n",
    "\n",
    "Other than the optimizer, all other parameters will remain consistent for both models.\n",
    "\n",
    "#### Scoring Metric Used:\n",
    "*The mean squared error will be used as a scoring metric. The lower the error, the better the optimizer!*\n",
    "\n",
    "#### Regularization Technique Used:\n",
    "*Early stopping and L2 regularization were used to avoid overfitting*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1001, 5)\n",
      "(1001, 4)\n"
     ]
    }
   ],
   "source": [
    "hidden_layer        = (512, 512, 512) # Hidden layers and nodes, per layer\n",
    "regularization_rate = 0.00001         # Rate for L2 regularization\n",
    "learning_rate_start = 0.01            # Initial learning rate\n",
    "learning_rate_mode  = 'adaptive'      # Mode for changing learning rate\n",
    "batch_size          = 128             # Size of batch for one update\n",
    "tolerance           = 1e-6            # Tolerance level for regressor\n",
    "max_iteration       = 1000            # Maximum number of iterations before stopping\n",
    "no_change_tolerance = 10              # Stop if no significant change happens in this number of iterations\n",
    "\n",
    "# n_iter_no_change=10\n",
    "\n",
    "model_adm = MLPRegressor(hidden_layer_sizes=hidden_layer, solver='adam', alpha=regularization_rate,\n",
    "                          batch_size=batch_size, learning_rate=learning_rate_mode,\n",
    "                          learning_rate_init=learning_rate_start, max_iter=max_iteration, tol=tolerance,\n",
    "                          verbose=True, early_stopping=True, validation_fraction=valid_ratio,\n",
    "                          n_iter_no_change=no_change_tolerance)\n",
    "print(training_input.shape)\n",
    "print(training_target.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Give The Models The Training Data And Fit Them!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Adam Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 4154.78541114\n",
      "Validation score: 0.693364\n",
      "Iteration 2, loss = 146.76765705\n",
      "Validation score: 0.535554\n",
      "Iteration 3, loss = 57.23545660\n",
      "Validation score: 0.694966\n",
      "Iteration 4, loss = 20.80334419\n",
      "Validation score: 0.954886\n",
      "Iteration 5, loss = 4.74353649\n",
      "Validation score: 0.993402\n",
      "Iteration 6, loss = 1.16946092\n",
      "Validation score: 0.993453\n",
      "Iteration 7, loss = 1.29222055\n",
      "Validation score: 0.991987\n",
      "Iteration 8, loss = 2.72631533\n",
      "Validation score: 0.986645\n",
      "Iteration 9, loss = 1.74708249\n",
      "Validation score: 0.944879\n",
      "Iteration 10, loss = 3.38698612\n",
      "Validation score: 0.992483\n",
      "Iteration 11, loss = 2.07907645\n",
      "Validation score: 0.993564\n",
      "Iteration 12, loss = 0.98347800\n",
      "Validation score: 0.993853\n",
      "Iteration 13, loss = 0.79013128\n",
      "Validation score: 0.988073\n",
      "Iteration 14, loss = 1.11792083\n",
      "Validation score: 0.991162\n",
      "Iteration 15, loss = 0.95003251\n",
      "Validation score: 0.990534\n",
      "Iteration 16, loss = 1.00271607\n",
      "Validation score: 0.993762\n",
      "Iteration 17, loss = 0.81937022\n",
      "Validation score: 0.993823\n",
      "Iteration 18, loss = 0.78202154\n",
      "Validation score: 0.993789\n",
      "Iteration 19, loss = 0.76739249\n",
      "Validation score: 0.993778\n",
      "Iteration 20, loss = 0.74937035\n",
      "Validation score: 0.992684\n",
      "Iteration 21, loss = 0.87325076\n",
      "Validation score: 0.990338\n",
      "Iteration 22, loss = 0.92320353\n",
      "Validation score: 0.985365\n",
      "Iteration 23, loss = 1.35786832\n",
      "Validation score: 0.992036\n",
      "Validation score did not improve more than tol=0.000001 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPRegressor(activation='relu', alpha=1e-05, batch_size=128, beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(512, 512, 512), learning_rate='adaptive',\n",
       "       learning_rate_init=0.01, max_iter=1000, momentum=0.9,\n",
       "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "       random_state=None, shuffle=True, solver='adam', tol=1e-06,\n",
       "       validation_fraction=0.1, verbose=True, warm_start=False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_adm.fit(training_input, training_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adam's Mean-Squared-Error: 1.262530059018131\n"
     ]
    }
   ],
   "source": [
    "predictions_adm = model_adm.predict(testing_input)\n",
    "mse_adm = metrics.mean_squared_error(predictions_adm,testing_target)\n",
    "print(\"Adam's Mean-Squared-Error:\", mse_adm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction sample for 3 instances \n",
    " similarity justification: As seen in the previous cell the MSE is low which means that the network is able to predict the values highly similar to the target values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions: [[55.69142674 55.91490474 55.8229445  55.77710291]\n",
      " [67.90431168 68.10460985 68.06071851 68.01757812]\n",
      " [91.19786121 91.3536487  91.4129308  91.37371288]\n",
      " [53.3469709  53.57091512 53.47235772 53.42966888]]\n",
      "\n",
      "targets [[55.2159 55.3611 55.8063 56.0192]\n",
      " [68.2958 68.3745 68.4926 68.7289]\n",
      " [90.5851 87.7391 84.913  86.6644]\n",
      " [53.5412 53.9691 53.0938 52.1504]]\n"
     ]
    }
   ],
   "source": [
    "print(\"predictions:\",predictions_adm[:4])\n",
    "print(\"\\ntargets\",testing_target[:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
