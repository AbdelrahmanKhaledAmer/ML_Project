{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2\n",
    "## Stock Prices Time Series Prediction\n",
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data into memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('sp500.csv')\n",
    "data = data.drop(['Unnamed: 0'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix = data.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find Highest correlation\n",
    "Get the single column with the highest correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_correlations = np.array(correlation_matrix[['SP500']])[1:]\n",
    "correlation_index = np.argmax(sp_correlations) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract The Desired Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desired_stock = data.iloc[:, correlation_index]\n",
    "\n",
    "input_set_1d  = np.array(desired_stock)\n",
    "output_set_1d = np.array(desired_stock.shift(-5).dropna())\n",
    "\n",
    "input_set  = [] # Process input_set_1d\n",
    "output_set = [] # Process output_set_1d\n",
    "\n",
    "train_ratio = 0.8\n",
    "test_ratio  = 0.2\n",
    "valid_ratio = 0.1 # Will be used in the MLPClassifier to take 10% of the training data as validation\n",
    "\n",
    "training_input,testing_input,training_target,testing_target = train_test_split(input_set,output_set,\n",
    "                                                                               test_size=test_ratio,\n",
    "                                                                               random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Linear regressor\n",
    "Two multilayer perceptrons. One using a stochastic gradient descent optimizer, and the other using an adam optimizer.\n",
    "\n",
    "Other than the optimizer, all other parameters will remain consistent for both models.\n",
    "\n",
    "#### Scoring Metric Used:\n",
    "*The mean suared error will be used as a scoring metric. The lower the error, the better the optimizer!*\n",
    "\n",
    "#### Regularization Technique Used:\n",
    "*L2 regularization was used to avoid overfitting*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_layer        = (512, 512, 512) # Hidden layers and nodes, per layer\n",
    "regularization_rate = 0.00001         # Rate for L2 regularization\n",
    "learning_rate_start = 0.01            # Initial learning rate\n",
    "learning_rate_mode  = 'adaptive'      # Mode for changing learning rate\n",
    "batch_size          = 128             # Size of batch for one update\n",
    "tolerance           = 1e-6            # Tolerance level for regressor\n",
    "max_iteration       = 1000            # Maximum number of iterations before stopping\n",
    "no_change_tolerance = 10              # Stop if no significant change happens in this number of iterations\n",
    "\n",
    "# n_iter_no_change=10\n",
    "\n",
    "model_adm = MLPRegressor(hidden_layer_sizes=hidden_layer, solver='adam', alpha=regularization_rate,\n",
    "                          batch_size=batch_size, learning_rate=learning_rate_mode,\n",
    "                          learning_rate_init=learning_rate_start, max_iter=max_iteration, tol=tolerance,\n",
    "                          verbose=True, early_stopping=True, validation_fraction=valid_ratio,\n",
    "                          n_iter_no_change=no_change_tolerance)\n",
    "model_sgd = MLPRegressor(hidden_layer_sizes=hidden_layer, solver='sgd', alpha=regularization_rate,\n",
    "                          batch_size=batch_size, learning_rate=learning_rate_mode,\n",
    "                          learning_rate_init=learning_rate_start, max_iter=max_iteration, tol=tolerance,\n",
    "                          verbose=True, early_stopping=True, validation_fraction=valid_ratio,\n",
    "                          n_iter_no_change=no_change_tolerance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
